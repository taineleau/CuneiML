{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing deepCORAL...\n",
      "The overall max F1 value in /graft2/code/yufei/Ancient_Artifact_Dating_front/wilds/logs/t23_iwildcam_deepCORAL_30_epoch_seed_2/val_eval.csv is: 0.5530638522549984 at epoch 23\n",
      "Corresponding test_eval acc_avg: 0.8939467072486877, F1 value: 0.40456152053834327\n",
      "Corresponding id_val_eval acc_avg: 0.9091801643371582, F1 value: 0.4861033686363874\n",
      "Corresponding id_test_eval acc_avg: 0.9305413961410522, F1 value: 0.5250553742600103\n",
      "Processing ERM...\n",
      "The overall max F1 value in /graft2/code/yufei/Ancient_Artifact_Dating_front/wilds/logs/t23_front_ERM_lr_3e-5_weight_decay_0_n_epochs_30/val_eval.csv is: 0.47926998718551367 at epoch 10\n",
      "Corresponding test_eval acc_avg: 0.8736077547073364, F1 value: 0.3482170402855048\n",
      "Corresponding id_val_eval acc_avg: 0.9518900513648987, F1 value: 0.805990818294073\n",
      "Corresponding id_test_eval acc_avg: 0.9473953247070312, F1 value: 0.6868888348615441\n",
      "Processing IRM...\n",
      "The overall max F1 value in /graft2/code/yufei/Ancient_Artifact_Dating_front/wilds/logs/t23_front_IRM_lr_3e-5_weight_decay_0_seed_2_lr_2e-5_epochs_30/val_eval.csv is: 0.533382316247063 at epoch 10\n",
      "Corresponding test_eval acc_avg: 0.8745762705802917, F1 value: 0.2830680958294542\n",
      "Corresponding id_val_eval acc_avg: 0.8880707025527954, F1 value: 0.44335628646676517\n",
      "Corresponding id_test_eval acc_avg: 0.9111338257789612, F1 value: 0.4341733184592986\n",
      "Processing groupDRO...\n",
      "The overall max F1 value in /graft2/code/yufei/Ancient_Artifact_Dating_front/wilds/logs/t23_front_groupDRO_lr_3e-5_weight_decay_0_seed_2_lr_3e-5_epochs_30/val_eval.csv is: 0.3473447064930419 at epoch 25\n",
      "Corresponding test_eval acc_avg: 0.8077481985092163, F1 value: 0.2793887447708216\n",
      "Corresponding id_val_eval acc_avg: 0.8699067234992981, F1 value: 0.6050187099387565\n",
      "Corresponding id_test_eval acc_avg: 0.8682329058647156, F1 value: 0.5046502469186764\n",
      "Processing t23_front_resnet_50_bs_32_res_448_CORAL_lr_3e-5_weight_decay_0_seed_2_n_epochs_30...\n",
      "The overall max F1 value in /graft2/code/yufei/Ancient_Artifact_Dating_front/wilds/logs/t23_front_resnet_50_bs_32_res_448_CORAL_lr_3e-5_weight_decay_0_seed_2_n_epochs_30/val_eval.csv is: 0.4898453023212106 at epoch 27\n",
      "Corresponding test_eval acc_avg: 0.9075060486793518, F1 value: 0.3485914724846022\n",
      "Corresponding id_val_eval acc_avg: 0.9175257682800293, F1 value: 0.5546906171268836\n",
      "Corresponding id_test_eval acc_avg: 0.9341164231300354, F1 value: 0.6315188951342955\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "def find_max_f1_in_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads the specified file, finds the maximum value in the last column (F1-macro_all),\n",
    "    and returns the maximum value along with the epoch.\n",
    "    \"\"\"\n",
    "    max_f1 = -float('inf')\n",
    "    max_epoch = None\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        # print(file_path)\n",
    "        next(reader)  # Skip the first row (header)\n",
    "        \n",
    "        for row in reader:\n",
    "            epoch = int(row[0])\n",
    "            f1_value = float(row[-1])\n",
    "            if f1_value > max_f1:\n",
    "                max_f1 = f1_value\n",
    "                max_epoch = epoch\n",
    "    \n",
    "    return max_f1, max_epoch\n",
    "\n",
    "\n",
    "def find_epoch_values_in_file(file_path, target_epoch):\n",
    "    \"\"\"\n",
    "    Reads the specified file, finds the values in the second (acc_avg) and last column (F1-macro_all)\n",
    "    for the given epoch.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        \n",
    "        reader = csv.reader(file)\n",
    "        \n",
    "        next(reader)  # Skip the first row (header)\n",
    "        \n",
    "        for row in reader:\n",
    "            epoch = int(row[0])\n",
    "            if epoch == target_epoch:\n",
    "                acc_avg = float(row[1])\n",
    "                f1_value = float(row[-1])\n",
    "                return acc_avg, f1_value\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "\n",
    "def process_directory(root_dir, sub_dir_str, file_name):\n",
    "    \"\"\"\n",
    "    Processes all files named `file_name` within subdirectories containing `sub_dir_str` in their names,\n",
    "    finds the maximum F1-macro_all value from `val_eval.csv` and the corresponding epoch, and then\n",
    "    retrieves the acc_avg and F1-macro_all values for the same epoch from `test_eval.csv`, `id_val_eval.csv`, and `id_test_eval.csv`.\n",
    "    \"\"\"\n",
    "    overall_max_f1 = -float('inf')\n",
    "    overall_max_file = \"\"\n",
    "    overall_max_epoch = None\n",
    "\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for dir_name in dirs:\n",
    "            if sub_dir_str in dir_name:\n",
    "                val_file_path = os.path.join(root, dir_name, file_name)\n",
    "                if os.path.exists(val_file_path):\n",
    "                    max_f1, max_epoch = find_max_f1_in_file(val_file_path)\n",
    "                    if max_f1 > overall_max_f1:\n",
    "                        overall_max_f1 = max_f1\n",
    "                        overall_max_file = val_file_path\n",
    "                        overall_max_epoch = max_epoch\n",
    "\n",
    "    if overall_max_epoch is not None:\n",
    "        test_file_path = overall_max_file.replace(\"val_eval.csv\", \"test_eval.csv\")\n",
    "        id_val_file_path = overall_max_file.replace(\"val_eval.csv\", \"id_val_eval.csv\")\n",
    "        id_test_file_path = overall_max_file.replace(\"val_eval.csv\", \"id_test_eval.csv\")\n",
    "        \n",
    "        test_acc, test_f1 = find_epoch_values_in_file(test_file_path, overall_max_epoch)\n",
    "        id_val_acc, id_val_f1 = find_epoch_values_in_file(id_val_file_path, overall_max_epoch)\n",
    "        id_test_acc, id_test_f1 = find_epoch_values_in_file(id_test_file_path, overall_max_epoch)\n",
    "\n",
    "        print(f\"The overall max F1 value in {overall_max_file} is: {overall_max_f1} at epoch {overall_max_epoch}\")\n",
    "        print(f\"Corresponding test_eval acc_avg: {test_acc}, F1 value: {test_f1}\")\n",
    "        print(f\"Corresponding id_val_eval acc_avg: {id_val_acc}, F1 value: {id_val_f1}\")\n",
    "        print(f\"Corresponding id_test_eval acc_avg: {id_test_acc}, F1 value: {id_test_f1}\")\n",
    "    else:\n",
    "        print(\"No valid epochs found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_directory = \"/graft2/code/yufei/Ancient_Artifact_Dating_front/wilds/logs\"  # root directory path\n",
    "\n",
    "    # deepCORAL\n",
    "    sub_directory_string = \"deepCORAL\"  # Replace with the substring to look for in subdirectory names\n",
    "    target_file_name = \"val_eval.csv\"  # the target file name\n",
    "    \n",
    "    print(f\"Processing {sub_directory_string}...\")\n",
    "    process_directory(root_directory, sub_directory_string, target_file_name)\n",
    "\n",
    "    #ERM\n",
    "    sub_directory_string = \"ERM\"  # Replace with the substring to look for in subdirectory names\n",
    "    \n",
    "    print(f\"Processing {sub_directory_string}...\")\n",
    "    process_directory(root_directory, sub_directory_string, target_file_name)\n",
    "\n",
    "    #IRM\n",
    "    sub_directory_string = \"IRM\"  # Replace with the substring to look for in subdirectory names\n",
    "    \n",
    "    print(f\"Processing {sub_directory_string}...\")\n",
    "    process_directory(root_directory, sub_directory_string, target_file_name)\n",
    "\n",
    "    #groupDRO\n",
    "    sub_directory_string = \"groupDRO\"  # Replace with the substring to look for in subdirectory names\n",
    "    \n",
    "    print(f\"Processing {sub_directory_string}...\")\n",
    "    process_directory(root_directory, sub_directory_string, target_file_name)\n",
    "\n",
    "    #\n",
    "    sub_directory_string = \"t23_front_resnet_50_bs_32_res_448_CORAL_lr_3e-5_weight_decay_0_seed_2_n_epochs_30\"  # Replace with the substring to look for in subdirectory names\n",
    "    \n",
    "    print(f\"Processing {sub_directory_string}...\")\n",
    "    process_directory(root_directory, sub_directory_string, target_file_name)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
